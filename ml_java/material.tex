% Created 2017-07-11 Ter 18:33
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\author{Evaldo Pereira de Carvalho Neto}
\date{\today}
\title{Material ML}
\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={Emacs 24.5.1 (Org mode 8.2.10)}}
\begin{document}

\maketitle
\tableofcontents


\section{ARTIGOS PARA LER}
\label{sec-1}

\subsection{{\bfseries\sffamily TODO} Word2Vec Explained}
\label{sec-1-1}
Ler e fazer um resumo do segundo link:
\url{https://levyomer.wordpress.com/2014/04/25/word2vec-explained-deriving-mikolov-et-al-s-negative-sampling-word-embedding-method/}

\subsubsection{Resumo}
\label{sec-1-1-1}

    A ideia do word2vec é encontrar palavras parecidas em um mesmo contexto dentro de um texto e fornecer um vetor, peso, para
as mesmas. Para isso é utilizado o modelo \textit{skip-gram} utilizando \textit{negative sampling},  não ficou claro mas essa solução possui
melhores resultados. Com isso ainda tenho como pendências:
\begin{itemize}
\item Pesquisar sobre \textit{skip-gram} e
\item Pesquisar sobre \textit{negative sampling}.
\end{itemize}

\subsection{{\bfseries\sffamily TODO} Distributed Representations of Words and Phrases and their Compositionality}
\label{sec-1-2}
Ler e fazer um resumo do seguinte artigo:
\url{http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf}
% Emacs 24.5.1 (Org mode 8.2.10)
\end{document}
